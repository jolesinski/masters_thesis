\chapter{Introduction}
\label{cha:introduction}

The aim of this work is to survey modern RGB-D image processing algorithms for model-based object instance recognition. Each method is analyzed with focus on its employment in time and resource constrained robotic environment. Based on provided performance evaluation, selected methods are used to develop a complete, applicable in robotics, object recognition system.

The first chapter provides project background. A formal problem statement is followed by a brief literature review, introducing the main categorization of solution proposals into feature and template matching techniques. After outlining the scientific context of this work, software libraries and tools for RGB-D image processing used throughout the project are presented. Algorithm evaluation methodology, reference dataset and hardware used for performance assessment are summarized at the end of this chapter.

Second chapter introduces common pre-processing techniques for RGB-D images. At first, different data representation and conversion methods are discussed. Fundamental concepts in further processing, including neighborhood selection and surface normal estimation are introduced and evaluated afterwards. To finalize this chapter, different noise types encountered in RGB-D data are discussed together with their corresponding filtering methods.
 
Model fitting with sparse feature matching algorithms is presented in chapter three. Selected keypoint detectors and descriptors of both color and shape modalities are compared. Efficient matching technique is provided. Correspondence clustering. Pose estimation methods are evaluated.

Template matching methods are discussed in the following chapter. Global features. Linemod. Bag of words. Neural networks.

Postprocessing. Pose refinement. Hypothesis verification.

Applications.

%---------------------------------------------------------------------------

\section{Problem statement}
\label{sec:problem}

%TODO: division to category/instancem from Szelski 14.3
Broad topic, \cite{szeliski}.

Given an input image and an object of interest, the task of object recognition is to provide answer to the following questions:
\begin{itemize}
\item Is the queried object \textit{present} in the image?
\item If it is, then what is the \textit{pose} of the object?
\end{itemize}
If the object has the properties of a rigid body, its pose is given by the linear and angular position.


Object recognition is a process that comprises determination of both object instance presence and its pose in a given scene image.   

Robotics: why object recognition
Object recognition: why RGB-D

%% methods of depth acquisition
%% applications in robotics, mapping, 3d modeling


%---------------------------------------------------------------------------

\section{Related work}
\label{sec:related}

%look for similar cotributions
%survey (in robotics): if nothing may be descr/keypoints comparison
%generic, open source system: mention ORK, V4R etc

Survey of local methods \cite{surveyLocal}.
Pipelines \cite{recognitionTutorial,multiPipeline}.

%---------------------------------------------------------------------------

\section{Software tools}
\label{sec:software}

Throughout this work, most of the software was developed with an extensive use of the Point Cloud Library (PCL)\cite{Rusu_ICRA2011_PCL}, which is an open source C++ library for three dimensional image processing. Since 2011, it is developed by a large scientific community, maintained by the Open Perception foundation and delivered under BSD license. PCL provides implementations of a multitude of novel algorithms for 3D filtering, feature estimation, segmentation, registration and model fitting, together with tools for visualization and camera interfacing.

The Open Computer Vision (OpenCV)\cite{OpenCV} library was utilized as another source of implementation for the analysed algorithms. OpenCV, which is a more mature project, developed since 1999 is likewise delivered under open source BSD license. While PCL is mainly focused on volumetric data analysis, OpenCV provides a wide array of functions for 2D intensity and color image processing.

Modeling \cite{modellingV4R}
V4R \cite{multiPipeline}
% ROS
% Ecto

%---------------------------------------------------------------------------

\section{Test environment}
\label{sec:testhardware}

Timing perf hardware

Testing of implemented algorithms was done on two hardware platforms: an embedded computing board NVidia Jetson TK1 and personal laptop Lenovo Y50-70. Parameters of both computers are summarized in table [x]. 

\begin{table}[H]
\centering
\begin{tabular}{r c | c}
& NVidia Jetson TK1 & Lenovo Y50-70 \\ 
 \hline
 CPU:& ARM Cortex-A15 2.32GHz x4 & Intel Core i7-4720HQ 2.60GHz x4\\
 GPU:& NVIDIA Kepler GK20a & NVidia GeForce GTX 960M \\
 &with 192 SM3.2 CUDA cores& with 640 SM5 CUDA Maxwell cores\\
 &(upto 326 GFLOPS)&(upto xx GFLOPS)\\
 RAM:& 2GB DDR3L 933MHz 64 bit&  16GB DDR3L 1600MHz (4GB GPU 2.5Mhz 128bit)
\end{tabular}
\caption{Test hardware specification}
\label{tab:hardware}
\end{table}

Dataset Willow

Recognition system was validated against sample dataset from XXX, which provides full object models together with real world scene scans and ground truth position annotations. To 

% Multimodal blending sec. 3

%TODO:
Dataset own using V4R and Xtion sensor

% TODO:
Precision vs Recall, ROC curves from Szelski

%---------------------------------------------------------------------------